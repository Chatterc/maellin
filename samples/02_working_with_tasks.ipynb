{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Union\n",
    "\n",
    "os.chdir(\"./../\")\n",
    "import pandas as pd\n",
    "from maellin.tasks import Task\n",
    "from pandas.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== PARAMETERS ====================== #\n",
    "# First lets reference some data files for us to work with\n",
    "dimA = 'data/dim_a.csv'\n",
    "dimB = 'data/dim_b.csv'\n",
    "dimC = 'data/dim_c.csv'\n",
    "factTbl = 'data/fact_tbl.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== FUNCTIONS ====================== #\n",
    "# Now lets create some python functions that we will use to process some data\n",
    "def select_target_cols(df: pd.DataFrame, target_schema: List) -> pd.DataFrame:\n",
    "    df = df[target_schema]\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_composite_key(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['CompositeKey'] = df.CNo.map(str) + \"-\" \\\n",
    "        + df.BNo.map(str) + \"-\" \\\n",
    "        + df.ANo.map(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_table(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def join_dataframes(A: pd.DataFrame, B: pd.DataFrame, on: Union[str, List], how: str) -> pd.DataFrame:\n",
    "    df = A.merge(B, on=on, how=how)\n",
    "    return df\n",
    "\n",
    "\n",
    "def sink_output(df: pd.DataFrame, path: str) -> None:\n",
    "    df.to_csv(path)\n",
    "    return\n",
    "\n",
    "\n",
    "def drop_duplicates(df: pd.DataFrame, columns=List[str]) -> pd.DataFrame:\n",
    "    df = df.drop_duplicates(subset=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_store = Task(read_table)\n",
    "read_staff = Task(read_table)\n",
    "read_address = Task(read_table)\n",
    "read_country = Task(read_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== TASKS ====================== #\n",
    "\n",
    "# Now lets create a bunch of tasks by wrapping our functions\n",
    "read = Task(read_table)\n",
    "select = Task(select_target_cols)\n",
    "join = Task(join_dataframes)\n",
    "joinCust = Task(join_dataframes)\n",
    "joinBG = Task(join_dataframes)\n",
    "composite = Task(create_composite_key)\n",
    "sink = Task(sink_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 22:53:04,799 :: maellin.common.tasks.BaseTask :: INFO :: Validation Check Complete for select_target_cols\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================== EXECUTION ====================== #\n",
    "\n",
    "# Now that we have some tasks we can use some of the methods we defined\n",
    "# Lets see our validate method in action by using it\n",
    "select.validate(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "CompatibilityException",
     "evalue": "Validation Failed. Output of select_target_cols is incompatible with inputs from read_table",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCompatibilityException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Lets see what happens when we try to validate to tasks that are not compatible\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m read\u001b[39m.\u001b[39;49mvalidate(select)\n",
      "File \u001b[1;32mc:\\Users\\Chatt\\OneDrive\\Desktop\\maellin\\maellin\\common\\tasks.py:99\u001b[0m, in \u001b[0;36mBaseTask.validate\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m _val \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValidation Failed. Output of \u001b[39m\u001b[39m{\u001b[39;00mother\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[0;32m     98\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis incompatible with inputs from \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 99\u001b[0m     \u001b[39mraise\u001b[39;00m CompatibilityException(error)\n\u001b[0;32m    102\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mValidation Check Complete for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n",
      "\u001b[1;31mCompatibilityException\u001b[0m: Validation Failed. Output of select_target_cols is incompatible with inputs from read_table"
     ]
    }
   ],
   "source": [
    "# Lets see what happens when we try to validate to tasks that are not compatible\n",
    "read.validate(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 22:53:11,170 :: maellin.common.tasks.BaseTask :: INFO :: Task caa65d7f-af15-43aa-861d-d7c9f8279e6e :: Running read_table\n",
      "2022-11-01 22:53:11,178 :: maellin.common.tasks.BaseTask :: INFO :: Task cbdf4f05-75bc-4d01-b43e-16ba22752d4c :: Running select_target_cols\n",
      "2022-11-01 22:53:11,181 :: maellin.common.tasks.BaseTask :: INFO :: Task 4f0cfd2c-6132-424c-a8e9-e59d77fc19e7 :: Running join_dataframes\n",
      "   AId_x     BId  AId_y\n",
      "0    300  784955    300\n",
      "1    300  784955    406\n",
      "2    300  784955    412\n",
      "3    300  784955    784\n",
      "4    300  784955    787\n",
      "5    300  784955    842\n",
      "6    300  784955   1030\n",
      "7    300  784955   1034\n",
      "8    300  784955   1064\n",
      "9    300  784955   1156\n"
     ]
    }
   ],
   "source": [
    "# Lets run some tasks we created in a linear (sequential pipeline)\n",
    "df = read.run(path='maellin\\data\\dim_a.csv')\n",
    "df = select.run(df, ['AId', 'BId'])\n",
    "df = join.run(df, df, on='BId', how='left')\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Postgres Client with Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from psycopg import Connection\n",
    "from maellin.common.clients.postgres import PostgresClient\n",
    "from maellin.common.tasks import BaseTask as Task\n",
    "\n",
    "from typing import List, Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets write some functions to use for processing data from our DVD-Rental Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pack all this into a function that we can encapsulate within a set of task\n",
    "def setup_client(config_file, section) -> Connection:\n",
    "    client = PostgresClient()\n",
    "    cursor = client.connect_from_config(path=config_file, section=section)\n",
    "    return cursor\n",
    "\n",
    "def set_search_path(cursor, catalog, schema) -> Connection:\n",
    "    cursor.execute(f\"SET search_path TO {catalog}, {schema};\")\n",
    "    return cursor\n",
    "    \n",
    "def create_new_schema(cursor, schema) -> Connection:\n",
    "    cursor.execute(f\"CREATE SCHEMA IF NOT EXISTS {schema};\")\n",
    "    return cursor\n",
    "    \n",
    "def read_table(cursor, table) -> List[Tuple]:\n",
    "    tbl = cursor.execute(f\"SELECT * FROM {table};\").fetchall()\n",
    "    return tbl\n",
    "    \n",
    "def to_pandas_df(data) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Lets Encapsulate Those functions in as Pipeline Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can put our functions in tasks for our pipeline\n",
    "tsk_0 = Task(setup_client)\n",
    "tsk_1 = Task(set_search_path)\n",
    "tsk_2 = Task(create_new_schema)\n",
    "tsk_3 = Task(read_table)\n",
    "tsk_4 = Task(to_pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets execute this as a linear pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 22:53:39,579 :: maellin.common.tasks.BaseTask :: INFO :: Task 3f76d134-be68-41cd-ab56-80fb5b337238 :: Running setup_client\n",
      "2022-11-01 22:53:39,633 :: maellin.common.tasks.BaseTask :: INFO :: Task a189ddf9-3779-42e0-935e-493cac309cb1 :: Running set_search_path\n",
      "2022-11-01 22:53:39,634 :: maellin.common.tasks.BaseTask :: INFO :: Task 2234fa92-f5b8-4f96-8e91-cb1a81db7d77 :: Running read_table\n",
      "2022-11-01 22:53:39,640 :: maellin.common.tasks.BaseTask :: INFO :: Task 53a48f98-c9a4-4099-a5c5-ce6cc8ec4e5f :: Running to_pandas_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Penelope</td>\n",
       "      <td>Guiness</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nick</td>\n",
       "      <td>Wahlberg</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ed</td>\n",
       "      <td>Chase</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Davis</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Johnny</td>\n",
       "      <td>Lollobrigida</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1             2                       3\n",
       "0  1  Penelope       Guiness 2013-05-26 14:47:57.620\n",
       "1  2      Nick      Wahlberg 2013-05-26 14:47:57.620\n",
       "2  3        Ed         Chase 2013-05-26 14:47:57.620\n",
       "3  4  Jennifer         Davis 2013-05-26 14:47:57.620\n",
       "4  5    Johnny  Lollobrigida 2013-05-26 14:47:57.620"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = tsk_0.run(\".config\\.postgres\", 'postgresql')\n",
    "cursor = tsk_1.run(cursor=cursor, catalog='dvdrental', schema='public')\n",
    "data = tsk_3.run(cursor=cursor, table='actor')\n",
    "df = tsk_4.run(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But What about Task 2 that we did not use?\n",
    "\n",
    "Task 2 is for creating a new schema, possibly a target for our processed data to use as a sink.\n",
    "But putting task 2 in our linear pipeline feels awkward, it does not fit in well with the other steps.\n",
    "This is where pipeline branching (splitting the pipeline into separate directions becomes useful)\n",
    "\n",
    "## To use branching strategies in data processing we need a DAG!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93f728960881c0e95a58ff4f43d965588a90ef8f40f993ba145d129978fecb3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
